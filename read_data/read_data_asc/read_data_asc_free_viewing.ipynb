{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from itertools import groupby\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P006\n",
      "P008\n",
      "P020\n",
      "P036\n",
      "P063\n",
      "P065\n",
      "P070\n",
      "P072\n",
      "P074\n",
      "P076\n",
      "P086\n",
      "P094\n",
      "P103\n",
      "P106\n",
      "P109\n",
      "P112\n",
      "P150\n",
      "P157\n",
      "P160\n",
      "P170\n",
      "P171\n",
      "P172\n",
      "P173\n",
      "P176\n",
      "P177\n",
      "P182\n",
      "P183\n",
      "P186\n",
      "P188\n",
      "P190\n",
      "P194\n",
      "P201\n",
      "P202\n",
      "P203\n",
      "P204\n",
      "P205\n",
      "P207\n",
      "P208\n",
      "P210\n"
     ]
    }
   ],
   "source": [
    "pathlist = Path('../../asc_data_free_viewing').rglob('*.asc')\n",
    "task_data_df = []\n",
    "df_final = pd.DataFrame()\n",
    "# for all participant\n",
    "for path in pathlist:\n",
    "    participant= re.search(r\"(P\\d+)\", os.path.basename(str(path.stem))).group(1)\n",
    "    f = open(str(path), 'r') # 'r' = read\n",
    "    print(participant)\n",
    "    lines = f.read()\n",
    "    f.close()\n",
    "    # j = 4\n",
    "    # n = 30\n",
    "    indices = []\n",
    "    current_start_index = 0\n",
    "    not_list = []\n",
    "    for i in range(1):\n",
    "\n",
    "        index_init1 = re.search(r'free_viewing_experiment_start',lines[current_start_index:-1]).span()[1]\n",
    "        index_init2 = re.search(r'\\n',lines[current_start_index + index_init1:-1]).span()[1]\n",
    "        index_init =  current_start_index + index_init1 + index_init2\n",
    "\n",
    "        index_finit1 = re.search(r'free_viewing_experiment_end',lines[index_init:-1]).span()[0]\n",
    "        index_finit = index_init + index_finit1\n",
    "\n",
    "        indices.append([index_init, index_finit-1])\n",
    "        current_start_index = index_finit\n",
    "\n",
    "        # if(i + 1) % 5 == 0:\n",
    "        #     j = int(j/2)\n",
    "\n",
    "        new_vec = lines[index_init: index_finit-1].split(\"\\n\")\n",
    "        new_new_vec = []\n",
    "        #0 = blink, 1 fixation, 2 saccade\n",
    "        stateL = 0\n",
    "        stateR = 0\n",
    "        for k in range(1,len(new_vec)):\n",
    "            la = new_vec[k].split(\"\\t\")\n",
    "            if len(la) == 1:\n",
    "                \n",
    "                if 'SSACC L' in la[0]:\n",
    "                    stateL = 2\n",
    "                if 'SFIX L' in la[0]:\n",
    "                    stateL = 1\n",
    "                if 'SBLINK L' in la[0]:\n",
    "                    stateL = 0\n",
    "                if 'SSACC R' in la[0]:\n",
    "                    stateR = 2\n",
    "                if 'SFIX R' in la[0]:\n",
    "                    stateR = 1\n",
    "                if 'SBLINK R' in la[0]:\n",
    "                    stateR = 0\n",
    "            if len(la) == 9:\n",
    "                if any(marker in la[0] for marker in ['ESACC L', 'EFIX L', 'EBLINK L', 'ESACC R', 'EFIX R', 'EBLINK R']):\n",
    "                    continue\n",
    "                else:\n",
    "                    la[-1] = stateL\n",
    "                    la.append(stateR)\n",
    "                    new_new_vec.append(la)\n",
    "            if len(la) == 6:\n",
    "                if any(marker in la[0] for marker in ['ESACC L', 'EFIX L', 'EBLINK L', 'ESACC R', 'EFIX R', 'EBLINK R']):\n",
    "                    continue\n",
    "                else:\n",
    "                    la[-1] = stateL\n",
    "                    la.append(stateR)\n",
    "                    new_new_vec.append(la)\n",
    "\n",
    "        ls = [[np.nan if x == '   .' else x for x in y] for y in new_new_vec]\n",
    "        if len(ls)>0:\n",
    "            ls = np.swapaxes(ls,0,1)\n",
    "            current_trial = np.asarray(ls, dtype=float)\n",
    "            # if participant =='P205':\n",
    "            # print(len(current_trial))\n",
    "            if len(current_trial) == 10:\n",
    "                my_df = pd.DataFrame(list(np.swapaxes(np.array([current_trial[0][:],current_trial[4][:],current_trial[5][:],current_trial[-1][:]]),0,1)), columns=['Time','RX','RY','state'])\n",
    "            else:\n",
    "                # print(current_trial[7][:])\n",
    "                my_df = pd.DataFrame(list(np.swapaxes(np.array([current_trial[0][:],current_trial[1][:],current_trial[2][:],current_trial[5][:]]),0,1)), columns=['Time','RX','RY','state'])\n",
    "            my_df['participants'] = participant\n",
    "            interval_num = np.minimum((np.arange(len(my_df)) // 3000) + 1, 40)\n",
    "            my_df['interval_num'] = interval_num\n",
    "            # my_df.to_csv(\"./free_viewing/eyelink_data/\" + participant + \"_\" + str(interval_num) + \".csv\", index=False)\n",
    "            # my_df['FREQ']=j\n",
    "\n",
    "            task_data_df.append(my_df)\n",
    "            df_final = pd.concat([df_final,my_df], ignore_index=True)\n",
    "        else:\n",
    "            not_list.append(i)\n",
    "\n",
    "\n",
    "df_final.to_csv(\"../../processed_data/processed_data_asc_task_free_viewing.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>RX</th>\n",
       "      <th>RY</th>\n",
       "      <th>state</th>\n",
       "      <th>participants</th>\n",
       "      <th>interval_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50662247.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50662248.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50662249.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50662250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50662251.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682072</th>\n",
       "      <td>428301439.0</td>\n",
       "      <td>750.4</td>\n",
       "      <td>592.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>P210</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682073</th>\n",
       "      <td>428301440.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>P210</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682074</th>\n",
       "      <td>428301441.0</td>\n",
       "      <td>764.2</td>\n",
       "      <td>592.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>P210</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682075</th>\n",
       "      <td>428301442.0</td>\n",
       "      <td>773.2</td>\n",
       "      <td>592.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>P210</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682076</th>\n",
       "      <td>428301443.0</td>\n",
       "      <td>784.7</td>\n",
       "      <td>592.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>P210</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4682077 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time     RX     RY  state participants  interval_num\n",
       "0         50662247.0    NaN    NaN    0.0         P006             1\n",
       "1         50662248.0    NaN    NaN    0.0         P006             1\n",
       "2         50662249.0    NaN    NaN    0.0         P006             1\n",
       "3         50662250.0    NaN    NaN    0.0         P006             1\n",
       "4         50662251.0    NaN    NaN    0.0         P006             1\n",
       "...              ...    ...    ...    ...          ...           ...\n",
       "4682072  428301439.0  750.4  592.0    2.0         P210            40\n",
       "4682073  428301440.0  756.0  592.0    2.0         P210            40\n",
       "4682074  428301441.0  764.2  592.2    2.0         P210            40\n",
       "4682075  428301442.0  773.2  592.4    2.0         P210            40\n",
       "4682076  428301443.0  784.7  592.0    2.0         P210            40\n",
       "\n",
       "[4682077 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_final.groupby(['participants', 'interval_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_dict = {}\n",
    "for (participant, interval), group in grouped:\n",
    "    key = f\"{participant}_{interval}\"\n",
    "    groups_dict[key] = group\n",
    "    group.to_csv(f\"./free_viewing/eyelink_data/{key}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing block to array: could not convert string to float: '   .'\n",
      "Merged Free Viewing (Faces) ASC Data:\n",
      "    Time   RX   RY  state participants  interval_num\n",
      "0    0.0  0.0  0.0    0.0         P184             1\n",
      "1    0.0  0.0  0.0    1.0         P184             1\n",
      "2    0.0  0.0  0.0    1.0         P184             1\n",
      "3    0.0  0.0  0.0    0.0         P184             2\n",
      "4    0.0  0.0  0.0    2.0         P184             2\n",
      "5    0.0  0.0  0.0    2.0         P184             2\n",
      "6    0.0  0.0  0.0    0.0         P184             3\n",
      "7    0.0  0.0  0.0    1.0         P184             3\n",
      "8    0.0  0.0  0.0    1.0         P184             3\n",
      "9    0.0  0.0  0.0    0.0         P184             4\n",
      "10   0.0  0.0  2.0    1.0         P184             4\n",
      "11   0.0  2.0  2.0    1.0         P184             4\n",
      "12   0.0  0.0  0.0    0.0         P184             5\n",
      "13   0.0  0.0  0.0    1.0         P184             5\n",
      "14   0.0  0.0  0.0    1.0         P184             5\n",
      "15   0.0  0.0  0.0    0.0         P184             6\n",
      "16   0.0  0.0  0.0    1.0         P184             6\n",
      "17   0.0  0.0  0.0    1.0         P184             6\n",
      "18   0.0  0.0  0.0    0.0         P184             7\n",
      "19   0.0  0.0  0.0    2.0         P184             7\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def process_faces_interval_block(block_text, participant, interval_num):\n",
    "    \"\"\"\n",
    "    Process a block of text corresponding to one free viewing (faces) interval.\n",
    "    This function mimics the state‐processing from your ASC saccade code:\n",
    "      - Splits the block into lines.\n",
    "      - For each line, if it has one field (no tab), it updates state markers for left and right eyes.\n",
    "      - For lines with 9 fields (data lines), it replaces the last field with the current left state,\n",
    "        appends the right state, and collects these.\n",
    "    Returns a DataFrame with columns: Time, RX, RY, state, plus added participant and interval_num.\n",
    "    \"\"\"\n",
    "    lines = block_text.split(\"\\n\")\n",
    "    processed_lines = []\n",
    "    \n",
    "    # Initialize state markers: (0=blink, 1=fixation, 2=saccade)\n",
    "    stateL = 0\n",
    "    stateR = 0\n",
    "\n",
    "    # Process lines in the block (skip first line if header-like)\n",
    "    for line in lines:\n",
    "        # Split by tab.\n",
    "        fields = line.split(\"\\t\")\n",
    "        # If the line is a single field, update states:\n",
    "        if len(fields) == 1:\n",
    "            text = fields[0].strip().lower()\n",
    "            if 'ssacc l' in text:\n",
    "                stateL = 2\n",
    "            elif 'sfix l' in text:\n",
    "                stateL = 1\n",
    "            elif 'sblink l' in text:\n",
    "                stateL = 0\n",
    "            if 'ssacc r' in text:\n",
    "                stateR = 2\n",
    "            elif 'sfix r' in text:\n",
    "                stateR = 1\n",
    "            elif 'sblink r' in text:\n",
    "                stateR = 0\n",
    "        # If the line has 9 fields, assume it is a data line.\n",
    "        elif len(fields) == 9:\n",
    "            # Optionally, ignore lines with markers like 'esacc', 'efix', or 'eblink'\n",
    "            if any(marker in fields[0].lower() for marker in ['esacc l', 'efix l', 'eblink l',\n",
    "                                                              'esacc r', 'efix r', 'eblink r']):\n",
    "                continue\n",
    "            # Otherwise, update the fields: replace the last field with stateL and append stateR.\n",
    "            fields[-1] = str(stateL)\n",
    "            fields.append(str(stateR))\n",
    "            processed_lines.append(fields)\n",
    "    \n",
    "    # If no data lines were processed, return an empty DataFrame.\n",
    "    if not processed_lines:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Convert processed_lines to a numpy array and swap axes so that each row becomes one record.\n",
    "    arr = np.array(processed_lines)\n",
    "    # In your saccade code you assumed:\n",
    "    # arr[0][:] -> Time, arr[4][:] -> RX, arr[5][:] -> RY, and last row -> state.\n",
    "    # Adjust these indices if necessary; here we assume the same.\n",
    "    try:\n",
    "        # Extract columns and swap axes: each record becomes [Time, RX, RY, state]\n",
    "        data = np.swapaxes(np.array([arr[0, :].astype(float), arr[4, :].astype(float), \n",
    "                                      arr[5, :].astype(float), arr[-1, :].astype(float)]), 0, 1)\n",
    "    except Exception as e:\n",
    "        print(\"Error processing block to array:\", e)\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df_interval = pd.DataFrame(data, columns=['Time', 'RX', 'RY', 'state'])\n",
    "    df_interval['participants'] = participant\n",
    "    df_interval['interval_num'] = interval_num\n",
    "    return df_interval\n",
    "\n",
    "def process_faces_asc_file(asc_file):\n",
    "    \"\"\"\n",
    "    Process a faces ASC file for one participant.\n",
    "    \n",
    "    The ASC file contains both calibrated data and embedded messages.\n",
    "    This function:\n",
    "      1. Reads the entire file.\n",
    "      2. Extracts the global free viewing experiment boundaries using markers:\n",
    "            free_viewing_experiment_start and free_viewing_experiment_end.\n",
    "      3. Divides the block between these markers into 40 equal parts.\n",
    "      4. For each subinterval, processes the block to extract data and state (via process_faces_interval_block).\n",
    "      5. Returns a concatenated DataFrame with all intervals.\n",
    "    \"\"\"\n",
    "    with open(asc_file, 'r') as f:\n",
    "        full_text = f.read()\n",
    "    \n",
    "    # Extract global free viewing experiment boundaries.\n",
    "    start_match = re.search(r'free_viewing_experiment_start', full_text, re.IGNORECASE)\n",
    "    end_match = re.search(r'free_viewing_experiment_end', full_text, re.IGNORECASE)\n",
    "    if not start_match or not end_match:\n",
    "        print(f\"Free viewing boundaries not found in {asc_file}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get the indices for the experiment block.\n",
    "    exp_start_idx = start_match.end()\n",
    "    exp_end_idx = end_match.start()\n",
    "    exp_text = full_text[exp_start_idx:exp_end_idx]\n",
    "    \n",
    "    # Divide the experiment block into 40 intervals.\n",
    "    total_length = len(exp_text)\n",
    "    interval_count = 40\n",
    "    interval_length = total_length // interval_count  # integer division\n",
    "    \n",
    "    merged_intervals = []\n",
    "    # Extract participant ID.\n",
    "    participant_match = re.search(r\"(P\\d+)\", os.path.basename(asc_file))\n",
    "    participant = participant_match.group(1) if participant_match else \"\"\n",
    "    \n",
    "    for i in range(interval_count):\n",
    "        # Compute start and end indices in the experiment text.\n",
    "        start_idx = i * interval_length\n",
    "        # For the last interval, take until the end.\n",
    "        if i == interval_count - 1:\n",
    "            end_idx = total_length\n",
    "        else:\n",
    "            end_idx = (i + 1) * interval_length\n",
    "        interval_block = exp_text[start_idx:end_idx]\n",
    "        df_interval = process_faces_interval_block(interval_block, participant, i + 1)\n",
    "        if not df_interval.empty:\n",
    "            merged_intervals.append(df_interval)\n",
    "    \n",
    "    if merged_intervals:\n",
    "        return pd.concat(merged_intervals, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def main():\n",
    "    # Collect ASC files for faces task.\n",
    "    # Adjust the folder path as needed.\n",
    "    asc_files = list(Path('./sample_data').rglob('*.asc'))\n",
    "    df_all = pd.DataFrame()\n",
    "    \n",
    "    for asc_file in asc_files:\n",
    "        df_participant = process_faces_asc_file(str(asc_file))\n",
    "        if not df_participant.empty:\n",
    "            df_all = pd.concat([df_all, df_participant], ignore_index=True)\n",
    "    \n",
    "    if not df_all.empty:\n",
    "        df_all = df_all.sort_values(['participants', 'Time']).reset_index(drop=True)\n",
    "        df_all.to_csv(\"./processed_data/processed_data_asc_task_free_viewing.csv\", index=False)\n",
    "        print(\"Merged Free Viewing (Faces) ASC Data:\")\n",
    "        print(df_all.head(20))\n",
    "    else:\n",
    "        print(\"No data merged.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
