{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot Probe Fractals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_message_file(msg_file):\n",
    "    \"\"\"\n",
    "    Process the message file and extract event intervals.\n",
    "    \n",
    "    Returns a dictionary with:\n",
    "      - 'experiment': tuple (exp_start, exp_end)\n",
    "      - 'fixation': list of tuples (start, stop)\n",
    "      - 'fractals': list of tuples (start, stop, fractal) where fractal is 'L', 'R', or 'N'\n",
    "      - 'pause': list of tuples (start, stop)\n",
    "      \n",
    "    This function reads the file line by line, splits on the first whitespace to\n",
    "    separate the timestamp from the message, and then uses case-insensitive matching.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(msg_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # Split each line only once: timestamp and the entire message.\n",
    "            parts = line.split(maxsplit=1)\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            try:\n",
    "                timestamp = float(parts[0])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            message = parts[1]\n",
    "            data.append((timestamp, message))\n",
    "    \n",
    "    # Create a DataFrame from the data and sort by timestamp.\n",
    "    df_msg = pd.DataFrame(data, columns=['timestamp', 'message'])\n",
    "    df_msg.sort_values('timestamp', inplace=True)\n",
    "    df_msg.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    events = {\n",
    "        'experiment': None,\n",
    "        'fixation': [],\n",
    "        'fractals': [],\n",
    "        'pause': []\n",
    "    }\n",
    "    \n",
    "    # Temporary variables for event interval tracking.\n",
    "    fixation_start = None\n",
    "    fractals_start = None\n",
    "    fractal_side = None\n",
    "    pause_start = None\n",
    "    exp_start = None\n",
    "    exp_end = None\n",
    "\n",
    "    # Process each message row.\n",
    "    for idx, row in df_msg.iterrows():\n",
    "        ts = row['timestamp']\n",
    "        msg = row['message'].strip().lower()\n",
    "        \n",
    "        # Experiment boundaries: Use loose matching so slight variations are captured.\n",
    "        if \"dot probe fractals\" in msg and \"start\" in msg:\n",
    "            exp_start = ts\n",
    "        elif \"dot probe fractals\" in msg and \"end\" in msg:\n",
    "            exp_end = ts\n",
    "\n",
    "        # Fixation intervals.\n",
    "        if \"fixation_cross_start\" in msg:\n",
    "            fixation_start = ts\n",
    "        elif \"fixation_cross_stop\" in msg and fixation_start is not None:\n",
    "            events['fixation'].append((fixation_start, ts))\n",
    "            fixation_start = None\n",
    "\n",
    "        # fractals stimuli intervals.\n",
    "        if \"fractals_stimuli_start\" in msg:\n",
    "            fractals_start = ts\n",
    "            fractal_side = None  # Reset fractal\n",
    "        if \"fractal side:\" in msg:\n",
    "            m = re.search(r\"fractal side:\\s*(\\w+)\", msg, re.IGNORECASE)\n",
    "            if m:\n",
    "                emo = m.group(1).lower()\n",
    "                fractal_side = \"L\" if emo == \"left\" else \"R\"\n",
    "        if \"fractals_stimuli_stop\" in msg and fractals_start is not None:\n",
    "            # Default to \"N\" if no fractal was captured.\n",
    "            if fractal_side is None:\n",
    "                fractal_side = \"N\"\n",
    "            events['fractals'].append((fractals_start, ts, fractal_side))\n",
    "            fractals_start = None\n",
    "            fractal_side = None\n",
    "\n",
    "        # Pause intervals.\n",
    "        if \"pause_start\" in msg:\n",
    "            pause_start = ts\n",
    "        elif \"pause_stop\" in msg and pause_start is not None:\n",
    "            events['pause'].append((pause_start, ts))\n",
    "            pause_start = None\n",
    "\n",
    "    events['experiment'] = (exp_start, exp_end)\n",
    "    return events\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_flags(gaze_df, events):\n",
    "    \"\"\"\n",
    "    Given a gaze DataFrame and event intervals, assign flag and fractal_side.\n",
    "    Returns the DataFrame with added 'flag' and 'fractal_side' columns.\n",
    "    \"\"\"\n",
    "    # Initialize new columns.\n",
    "    gaze_df['flag'] = -1\n",
    "    gaze_df['fractal_side'] = \"N\"  # Default to \"N\" if no fractals side is applicable.\n",
    "    \n",
    "    # Apply flag 0 for fixation intervals.\n",
    "    for start, stop in events['fixation']:\n",
    "        mask = (gaze_df['Time'] >= start) & (gaze_df['Time'] <= stop)\n",
    "        gaze_df.loc[mask, 'flag'] = 0\n",
    "    \n",
    "    # Apply flag 1 for fractals stimuli intervals and assign fractals.\n",
    "    for start, stop, fractals in events['fractals']:\n",
    "        mask = (gaze_df['Time'] >= start) & (gaze_df['Time'] <= stop)\n",
    "        gaze_df.loc[mask, 'flag'] = 1\n",
    "        gaze_df.loc[mask, 'fractal_side'] = fractals  # \"L\", \"R\", or \"N\" if not captured.\n",
    "    \n",
    "    # Apply flag 2 for pause intervals.\n",
    "    for start, stop in events['pause']:\n",
    "        mask = (gaze_df['Time'] >= start) & (gaze_df['Time'] <= stop)\n",
    "        gaze_df.loc[mask, 'flag'] = 2\n",
    "    \n",
    "    return gaze_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_participant(gaze_file, msg_file):\n",
    "    \"\"\"\n",
    "    Process a single participant's files:\n",
    "      - Read the gaze file (columns: Time, calX, calY, rawX, rawY)\n",
    "      - Process the message file to extract event intervals.\n",
    "      - Filter gaze data to the experiment window.\n",
    "      - Assign flags and emotion_side.\n",
    "      - Add a 'participants' column.\n",
    "    Returns the processed gaze DataFrame.\n",
    "    \"\"\"\n",
    "    # Extract participant identifier (e.g., P006) from the filename.\n",
    "    match = re.search(r\"(P\\d+)\", os.path.basename(gaze_file))\n",
    "    if not match:\n",
    "        return None\n",
    "    participant_id = match.group(1)\n",
    "    \n",
    "    # Read the gaze file.\n",
    "    df_gaze = pd.read_csv(gaze_file, sep=r\"\\s+\", header=None, engine='python')\n",
    "    df_gaze.columns = ['Time', 'calX', 'calY', 'rawX', 'rawY']\n",
    "    df_gaze['Time'] = pd.to_numeric(df_gaze['Time'])\n",
    "    \n",
    "    # Add participants column.\n",
    "    df_gaze['participants'] = participant_id\n",
    "    \n",
    "    # Process message file to get event intervals.\n",
    "    events = process_message_file(msg_file)\n",
    "    # print(f\"Processed {participant_id}: {events}\")\n",
    "    # Filter gaze data to the experiment window.\n",
    "    exp_start, exp_end = events['experiment']\n",
    "    if exp_start is None or exp_end is None:\n",
    "        print(f\"Experiment boundaries not found for {participant_id}\")\n",
    "        return None\n",
    "    df_exp = df_gaze[(df_gaze['Time'] >= exp_start) & (df_gaze['Time'] <= exp_end)].copy()\n",
    "    \n",
    "    # Assign flags and emotion_side.\n",
    "    df_processed = assign_flags(df_exp, events)\n",
    "    return df_processed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect gaze and message files (assumes they are in the current directory).\n",
    "gaze_files = glob.glob(\"../../tiny_data/gaze_data_v6/gaze_directions_calibrated_*.txt\")\n",
    "msg_files = glob.glob(\"../../tiny_data/gaze_data_v6/gaze_messages_*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Processed Data:\n",
      "            Time      calX      calY    rawX   rawY participants  flag  \\\n",
      "0   1.740664e+09  -1853.37   3407.44  209.66  13.39         P004     0   \n",
      "1   1.740664e+09  -1938.43   3551.15  209.61  13.39         P004     0   \n",
      "2   1.740664e+09  -1723.91   3247.95  209.69  13.35         P004     0   \n",
      "3   1.740664e+09  -1599.13   3007.43  209.80  13.35         P004     0   \n",
      "4   1.740664e+09  -1929.95   3333.85  209.79  13.50         P004     0   \n",
      "5   1.740664e+09  -1796.64   3135.86  209.86  13.49         P004     0   \n",
      "6   1.740664e+09  -1779.21   3161.56  209.82  13.45         P004     0   \n",
      "7   1.740664e+09  -1303.08   2411.66  210.26  13.39         P004     0   \n",
      "8   1.740664e+09  -2419.01   3589.66  209.97  13.84         P004     0   \n",
      "9   1.740664e+09  -1727.51   2809.81  210.19  13.65         P004     0   \n",
      "10  1.740664e+09  -1996.00   3202.88  209.98  13.66         P004     0   \n",
      "11  1.740664e+09  -1892.34   3075.45  210.03  13.64         P004     0   \n",
      "12  1.740664e+09  -2033.17   3196.45  210.03  13.71         P004     1   \n",
      "13  1.740664e+09  -1779.32   2949.22  210.06  13.60         P004     1   \n",
      "14  1.740664e+09  -1819.26   2967.84  210.08  13.63         P004     1   \n",
      "15  1.740664e+09  -2115.19   3298.98  210.00  13.72         P004     1   \n",
      "16  1.740664e+09  -1825.16   2974.18  210.08  13.64         P004     1   \n",
      "17  1.740664e+09  -1882.58   2991.49  210.12  13.69         P004     1   \n",
      "18  1.740664e+09 -47453.58  85156.39  208.70  13.40         P004     1   \n",
      "19  1.740664e+09   4253.07  -6792.47  208.38  13.54         P004     1   \n",
      "\n",
      "   fractal_side  \n",
      "0             N  \n",
      "1             N  \n",
      "2             N  \n",
      "3             N  \n",
      "4             N  \n",
      "5             N  \n",
      "6             N  \n",
      "7             N  \n",
      "8             N  \n",
      "9             N  \n",
      "10            N  \n",
      "11            N  \n",
      "12            L  \n",
      "13            L  \n",
      "14            L  \n",
      "15            L  \n",
      "16            L  \n",
      "17            L  \n",
      "18            L  \n",
      "19            L  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Map each participant id to its corresponding message file.\n",
    "msg_dict = {}\n",
    "for mf in msg_files:\n",
    "    match = re.search(r\"(P\\d+)\", os.path.basename(mf))\n",
    "    if match:\n",
    "        participant_id = match.group(1)\n",
    "        msg_dict[participant_id] = mf\n",
    "\n",
    "# Process each participant's data and combine into a single DataFrame.\n",
    "df_list = []\n",
    "for gf in gaze_files:\n",
    "    match = re.search(r\"(P\\d+)\", os.path.basename(gf))\n",
    "    if not match:\n",
    "        continue\n",
    "    participant_id = match.group(1)\n",
    "    if participant_id in msg_dict:\n",
    "        processed = process_participant(gf, msg_dict[participant_id])\n",
    "        if processed is not None:\n",
    "            df_list.append(processed)\n",
    "    else:\n",
    "        print(f\"No message file found for participant {participant_id}\")\n",
    "\n",
    "if df_list:\n",
    "    df_final = pd.concat(df_list, ignore_index=True)\n",
    "    # Optionally sort by participant and Time.\n",
    "    df_final = df_final.sort_values(['participants', 'Time']).reset_index(drop=True)\n",
    "    # Save the final DataFrame to a CSV file.\n",
    "    df_final.to_csv(\"../../processed_data/processed_data_tiny_task_fractals_all.csv\", index=False)\n",
    "    print(\"Combined Processed Data:\")\n",
    "    print(df_final.head(20))\n",
    "else:\n",
    "    print(\"No data processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
