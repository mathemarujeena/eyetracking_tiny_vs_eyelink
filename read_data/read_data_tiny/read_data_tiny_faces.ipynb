{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot Probe Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_message_file(msg_file):\n",
    "    \"\"\"\n",
    "    Process the message file and extract event intervals.\n",
    "    \n",
    "    Returns a dictionary with:\n",
    "      - 'experiment': tuple (exp_start, exp_end)\n",
    "      - 'fixation': list of tuples (start, stop)\n",
    "      - 'faces': list of tuples (start, stop, emotion) where emotion is 'L', 'R', or 'N'\n",
    "      - 'pause': list of tuples (start, stop)\n",
    "      \n",
    "    This function reads the file line by line, splits on the first whitespace to\n",
    "    separate the timestamp from the message, and then uses case-insensitive matching.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(msg_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # Split each line only once: timestamp and the entire message.\n",
    "            parts = line.split(maxsplit=1)\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            try:\n",
    "                timestamp = float(parts[0])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            message = parts[1]\n",
    "            data.append((timestamp, message))\n",
    "    \n",
    "    # Create a DataFrame from the data and sort by timestamp.\n",
    "    df_msg = pd.DataFrame(data, columns=['timestamp', 'message'])\n",
    "    df_msg.sort_values('timestamp', inplace=True)\n",
    "    df_msg.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    events = {\n",
    "        'experiment': None,\n",
    "        'fixation': [],\n",
    "        'faces': [],\n",
    "        'pause': []\n",
    "    }\n",
    "    \n",
    "    # Temporary variables for event interval tracking.\n",
    "    fixation_start = None\n",
    "    faces_start = None\n",
    "    faces_emotion = None\n",
    "    pause_start = None\n",
    "    exp_start = None\n",
    "    exp_end = None\n",
    "\n",
    "    # Process each message row.\n",
    "    for idx, row in df_msg.iterrows():\n",
    "        ts = row['timestamp']\n",
    "        msg = row['message'].strip().lower()\n",
    "        \n",
    "        # Experiment boundaries: Use loose matching so slight variations are captured.\n",
    "        if \"dot probe faces\" in msg and \"start\" in msg:\n",
    "            exp_start = ts\n",
    "        elif \"dot probe faces\" in msg and \"end\" in msg:\n",
    "            exp_end = ts\n",
    "\n",
    "        # Fixation intervals.\n",
    "        if \"fixation_cross_start\" in msg:\n",
    "            fixation_start = ts\n",
    "        elif \"fixation_cross_stop\" in msg and fixation_start is not None:\n",
    "            events['fixation'].append((fixation_start, ts))\n",
    "            fixation_start = None\n",
    "\n",
    "        # Faces stimuli intervals.\n",
    "        if \"faces_stimuli_start\" in msg:\n",
    "            faces_start = ts\n",
    "            faces_emotion = None  # Reset emotion\n",
    "        if \"emotion_side:\" in msg:\n",
    "            m = re.search(r\"emotion_side:\\s*(\\w+)\", msg, re.IGNORECASE)\n",
    "            if m:\n",
    "                emo = m.group(1).lower()\n",
    "                faces_emotion = \"L\" if emo == \"left\" else \"R\"\n",
    "        if \"faces_stimuli_stop\" in msg and faces_start is not None:\n",
    "            # Default to \"N\" if no emotion was captured.\n",
    "            if faces_emotion is None:\n",
    "                faces_emotion = \"N\"\n",
    "            events['faces'].append((faces_start, ts, faces_emotion))\n",
    "            faces_start = None\n",
    "            faces_emotion = None\n",
    "\n",
    "        # Pause intervals.\n",
    "        if \"pause_start\" in msg:\n",
    "            pause_start = ts\n",
    "        elif \"pause_stop\" in msg and pause_start is not None:\n",
    "            events['pause'].append((pause_start, ts))\n",
    "            pause_start = None\n",
    "\n",
    "    events['experiment'] = (exp_start, exp_end)\n",
    "    return events\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_flags(gaze_df, events):\n",
    "    \"\"\"\n",
    "    Given a gaze DataFrame and event intervals, assign flag and emotion_side.\n",
    "    Returns the DataFrame with added 'flag' and 'emotion_side' columns.\n",
    "    \"\"\"\n",
    "    # Initialize new columns.\n",
    "    gaze_df['flag'] = -1\n",
    "    gaze_df['emotion_side'] = \"N\"  # Default to \"N\" if no emotion side is applicable.\n",
    "    \n",
    "    # Apply flag 0 for fixation intervals.\n",
    "    for start, stop in events['fixation']:\n",
    "        mask = (gaze_df['Time'] >= start) & (gaze_df['Time'] <= stop)\n",
    "        gaze_df.loc[mask, 'flag'] = 0\n",
    "    \n",
    "    # Apply flag 1 for faces stimuli intervals and assign emotion.\n",
    "    for start, stop, emotion in events['faces']:\n",
    "        mask = (gaze_df['Time'] >= start) & (gaze_df['Time'] <= stop)\n",
    "        gaze_df.loc[mask, 'flag'] = 1\n",
    "        gaze_df.loc[mask, 'emotion_side'] = emotion  # \"L\", \"R\", or \"N\" if not captured.\n",
    "    \n",
    "    # Apply flag 2 for pause intervals.\n",
    "    for start, stop in events['pause']:\n",
    "        mask = (gaze_df['Time'] >= start) & (gaze_df['Time'] <= stop)\n",
    "        gaze_df.loc[mask, 'flag'] = 2\n",
    "    \n",
    "    return gaze_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_participant(gaze_file, msg_file):\n",
    "    \"\"\"\n",
    "    Process a single participant's files:\n",
    "      - Read the gaze file (columns: Time, calX, calY, rawX, rawY)\n",
    "      - Process the message file to extract event intervals.\n",
    "      - Filter gaze data to the experiment window.\n",
    "      - Assign flags and emotion_side.\n",
    "      - Add a 'participants' column.\n",
    "    Returns the processed gaze DataFrame.\n",
    "    \"\"\"\n",
    "    # Extract participant identifier (e.g., P006) from the filename.\n",
    "    match = re.search(r\"(P\\d+)\", os.path.basename(gaze_file))\n",
    "    if not match:\n",
    "        return None\n",
    "    participant_id = match.group(1)\n",
    "    \n",
    "    # Read the gaze file.\n",
    "    df_gaze = pd.read_csv(gaze_file, sep=r\"\\s+\", header=None, engine='python')\n",
    "    df_gaze.columns = ['Time', 'calX', 'calY', 'rawX', 'rawY']\n",
    "    df_gaze['Time'] = pd.to_numeric(df_gaze['Time'])\n",
    "    \n",
    "    # Add participants column.\n",
    "    df_gaze['participants'] = participant_id\n",
    "    \n",
    "    # Process message file to get event intervals.\n",
    "    events = process_message_file(msg_file)\n",
    "    # print(f\"Processed {participant_id}: {events}\")\n",
    "    # Filter gaze data to the experiment window.\n",
    "    exp_start, exp_end = events['experiment']\n",
    "    if exp_start is None or exp_end is None:\n",
    "        print(f\"Experiment boundaries not found for {participant_id}\")\n",
    "        return None\n",
    "    df_exp = df_gaze[(df_gaze['Time'] >= exp_start) & (df_gaze['Time'] <= exp_end)].copy()\n",
    "    \n",
    "    # Assign flags and emotion_side.\n",
    "    df_processed = assign_flags(df_exp, events)\n",
    "    return df_processed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect gaze and message files (assumes they are in the current directory).\n",
    "gaze_files = glob.glob(\"../../tiny_data/gaze_data_v6/gaze_directions_calibrated_*.txt\")\n",
    "msg_files = glob.glob(\"../../tiny_data/gaze_data_v6/gaze_messages_*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Processed Data:\n",
      "            Time     calX     calY    rawX   rawY participants  flag  \\\n",
      "0   1.740664e+09  -548.70  -767.50  206.84  12.29         P004     0   \n",
      "1   1.740664e+09 -1085.37 -1398.90  207.14  12.06         P004     0   \n",
      "2   1.740664e+09  -288.91  -934.85  206.98  12.49         P004     0   \n",
      "3   1.740664e+09  -573.69  -950.21  206.97  12.28         P004     0   \n",
      "4   1.740664e+09  -670.67 -1212.10  207.10  12.25         P004     0   \n",
      "5   1.740664e+09  -688.50 -1326.02  207.15  12.24         P004     0   \n",
      "6   1.740664e+09  -890.46 -1385.55  207.15  12.15         P004     0   \n",
      "7   1.740664e+09  -629.07 -1094.53  207.05  12.26         P004     0   \n",
      "8   1.740664e+09  -791.20 -1400.31  207.17  12.20         P004     0   \n",
      "9   1.740664e+09  -508.46  -671.82  206.76  12.31         P004     0   \n",
      "10  1.740664e+09  -683.66  -824.34  206.88  12.20         P004     0   \n",
      "11  1.740664e+09  -519.91  -605.48  206.70  12.30         P004     0   \n",
      "12  1.740664e+09  -856.65 -1142.97  207.05  12.14         P004     0   \n",
      "13  1.740664e+09  -446.85  -724.53  206.81  12.36         P004     0   \n",
      "14  1.740664e+09  -920.12 -2442.06  207.44  12.22         P004     1   \n",
      "15  1.740664e+09  -588.44  -810.57  206.87  12.26         P004     1   \n",
      "16  1.740664e+09  -535.81 -1142.00  207.08  12.32         P004     1   \n",
      "17  1.740664e+09  -659.72 -1197.12  207.10  12.25         P004     1   \n",
      "18  1.740664e+09  -441.46  -968.72  206.99  12.37         P004     1   \n",
      "19  1.740664e+09  -828.73 -1185.30  207.07  12.16         P004     1   \n",
      "\n",
      "   emotion_side  \n",
      "0             N  \n",
      "1             N  \n",
      "2             N  \n",
      "3             N  \n",
      "4             N  \n",
      "5             N  \n",
      "6             N  \n",
      "7             N  \n",
      "8             N  \n",
      "9             N  \n",
      "10            N  \n",
      "11            N  \n",
      "12            N  \n",
      "13            N  \n",
      "14            L  \n",
      "15            L  \n",
      "16            L  \n",
      "17            L  \n",
      "18            L  \n",
      "19            L  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Map each participant id to its corresponding message file.\n",
    "msg_dict = {}\n",
    "for mf in msg_files:\n",
    "    match = re.search(r\"(P\\d+)\", os.path.basename(mf))\n",
    "    if match:\n",
    "        participant_id = match.group(1)\n",
    "        msg_dict[participant_id] = mf\n",
    "\n",
    "# Process each participant's data and combine into a single DataFrame.\n",
    "df_list = []\n",
    "for gf in gaze_files:\n",
    "    match = re.search(r\"(P\\d+)\", os.path.basename(gf))\n",
    "    if not match:\n",
    "        continue\n",
    "    participant_id = match.group(1)\n",
    "    if participant_id in msg_dict:\n",
    "        processed = process_participant(gf, msg_dict[participant_id])\n",
    "        if processed is not None:\n",
    "            df_list.append(processed)\n",
    "    else:\n",
    "        print(f\"No message file found for participant {participant_id}\")\n",
    "\n",
    "if df_list:\n",
    "    df_final = pd.concat(df_list, ignore_index=True)\n",
    "    # Optionally sort by participant and Time.\n",
    "    df_final = df_final.sort_values(['participants', 'Time']).reset_index(drop=True)\n",
    "    # Save the final DataFrame to a CSV file.\n",
    "    df_final.to_csv(\"../../processed_data/processed_data_tiny_task_faces_all.csv\", index=False)\n",
    "    print(\"Combined Processed Data:\")\n",
    "    print(df_final.head(20))\n",
    "else:\n",
    "    print(\"No data processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
