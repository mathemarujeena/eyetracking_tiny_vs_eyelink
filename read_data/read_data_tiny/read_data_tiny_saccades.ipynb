{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data:\n",
      "            Time      calX      calY    rawX   rawY participants time_delay  \\\n",
      "0   1.740664e+09 -16863.08  17354.46  209.78  14.93         P004    200/240   \n",
      "1   1.740664e+09  32583.36 -28839.24  209.81  15.64         P004    200/240   \n",
      "2   1.740664e+09  -5412.85   5737.86  210.38  15.02         P004    200/240   \n",
      "3   1.740664e+09  -7514.72   7654.70  210.26  15.15         P004    200/240   \n",
      "4   1.740664e+09  -3383.13   3860.69  210.67  14.80         P004    200/240   \n",
      "5   1.740664e+09  -2677.00   3230.12  210.81  14.61         P004    200/240   \n",
      "6   1.740664e+09  -2800.57   3435.30  210.61  14.51         P004    200/240   \n",
      "7   1.740664e+09  -3261.00   3869.62  210.51  14.60         P004    200/240   \n",
      "8   1.740664e+09  -2259.56   2962.63  210.69  14.29         P004    200/240   \n",
      "9   1.740664e+09  -3557.53   4203.37  210.39  14.59         P004    200/240   \n",
      "10  1.740664e+09  -2594.82   3268.78  210.62  14.41         P004    200/240   \n",
      "11  1.740664e+09  -3375.45   4082.27  210.35  14.50         P004    200/240   \n",
      "12  1.740664e+09  -2752.49   3482.28  210.47  14.37         P004    200/240   \n",
      "13  1.740664e+09  -3267.73   3956.74  210.40  14.50         P004    200/240   \n",
      "14  1.740664e+09  -2341.81   3076.52  210.60  14.27         P004    200/240   \n",
      "15  1.740664e+09  -3732.82   4477.64  210.24  14.50         P004    200/240   \n",
      "16  1.740664e+09  -2219.70   3034.81  210.50  14.13         P004    200/240   \n",
      "17  1.740664e+09  -3567.64   4376.56  210.20  14.41         P004    200/240   \n",
      "18  1.740664e+09  -2410.92   3246.48  210.40  14.16         P004    200/240   \n",
      "19  1.740664e+09  -3637.22   4475.67  210.16  14.39         P004    200/240   \n",
      "\n",
      "       X  Y  interval_num  \n",
      "0   0.65  0             1  \n",
      "1   0.65  0             1  \n",
      "2   0.65  0             1  \n",
      "3   0.65  0             1  \n",
      "4   0.65  0             1  \n",
      "5   0.65  0             1  \n",
      "6   0.65  0             1  \n",
      "7   0.65  0             1  \n",
      "8   0.65  0             1  \n",
      "9   0.65  0             1  \n",
      "10  0.65  0             1  \n",
      "11  0.65  0             1  \n",
      "12  0.65  0             1  \n",
      "13  0.65  0             1  \n",
      "14  0.65  0             1  \n",
      "15  0.65  0             1  \n",
      "16  0.65  0             1  \n",
      "17  0.65  0             1  \n",
      "18  0.65  0             1  \n",
      "19  0.65  0             1  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_saccade_messages(msg_file):\n",
    "    \"\"\"\n",
    "    Process a saccade messages file and extract intervals between saccade_task_start and saccade_task_end,\n",
    "    ignoring any lines that pertain to the antisaccade task.\n",
    "    \n",
    "    For each interval, extract:\n",
    "      - start: timestamp of saccade_task_start\n",
    "      - end: timestamp of saccade_task_end\n",
    "      - time_delay: value from the \"time delay stimulus=XXX/240\" message\n",
    "      - X: x-coordinate from \"placement position=(x, y)\"\n",
    "      - Y: y-coordinate from \"placement position=(x, y)\"\n",
    "      \n",
    "    Returns a pandas DataFrame with one row per saccade interval.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    current_interval = {}\n",
    "    \n",
    "    with open(msg_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # Split the line into timestamp and the rest of the message.\n",
    "            parts = line.split(maxsplit=1)\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            try:\n",
    "                ts = float(parts[0])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            msg = parts[1].strip().lower()\n",
    "            # Skip any message related to antisaccade.\n",
    "            if \"anti_saccade\" in msg:\n",
    "                continue\n",
    "            \n",
    "            if \"saccade_task_start\" in msg:\n",
    "                current_interval = {\"start\": ts}\n",
    "            elif \"time delay stimulus=\" in msg:\n",
    "                m = re.search(r\"time delay stimulus=([^\\s]+)\", msg)\n",
    "                if m:\n",
    "                    current_interval[\"time_delay\"] = m.group(1)\n",
    "            elif \"placement position=\" in msg:\n",
    "                m = re.search(r\"placement position=\\(([^)]+)\\)\", msg)\n",
    "                if m:\n",
    "                    pos_str = m.group(1)  # e.g., \"0.65, 0\"\n",
    "                    pos_parts = [x.strip() for x in pos_str.split(',')]\n",
    "                    if len(pos_parts) == 2:\n",
    "                        current_interval[\"X\"] = pos_parts[0]\n",
    "                        current_interval[\"Y\"] = pos_parts[1]\n",
    "            elif \"saccade_task_end\" in msg:\n",
    "                current_interval[\"end\"] = ts\n",
    "                if all(key in current_interval for key in (\"start\", \"end\", \"time_delay\", \"X\", \"Y\")):\n",
    "                    data.append(current_interval.copy())\n",
    "                current_interval = {}\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def process_saccade_messages_with_participant(msg_file):\n",
    "    \"\"\"\n",
    "    Process a saccade message file and add the participant identifier.\n",
    "    \n",
    "    Returns a DataFrame with columns: start, end, time_delay, X, Y, participants.\n",
    "    \"\"\"\n",
    "    df = process_saccade_messages(msg_file)\n",
    "    m = re.search(r\"(P\\d+)\", os.path.basename(msg_file))\n",
    "    if m:\n",
    "        df[\"participants\"] = m.group(1)\n",
    "    else:\n",
    "        df[\"participants\"] = \"\"\n",
    "    return df\n",
    "\n",
    "def process_calibrated_file(cal_file):\n",
    "    \"\"\"\n",
    "    Process a calibrated gaze data file.\n",
    "    \n",
    "    The file should have five columns: Time, calX, calY, rawX, rawY.\n",
    "    Returns a DataFrame with an added 'participants' column.\n",
    "    \"\"\"\n",
    "    df_cal = pd.read_csv(cal_file, sep=r\"\\s+\", header=None, engine='python')\n",
    "    df_cal.columns = ['Time', 'calX', 'calY', 'rawX', 'rawY']\n",
    "    df_cal['Time'] = pd.to_numeric(df_cal['Time'])\n",
    "    m = re.search(r\"(P\\d+)\", os.path.basename(cal_file))\n",
    "    if m:\n",
    "        df_cal[\"participants\"] = m.group(1)\n",
    "    else:\n",
    "        df_cal[\"participants\"] = \"\"\n",
    "    return df_cal\n",
    "\n",
    "def merge_saccade_intervals_with_calibrated(cal_file, msg_file):\n",
    "    \"\"\"\n",
    "    Merge calibrated gaze data with saccade intervals for one participant.\n",
    "    \n",
    "    For each saccade interval (extracted from msg_file), this function selects all calibrated\n",
    "    gaze data rows (from cal_file) whose Time falls within the interval and annotates them with \n",
    "    the saccade properties: time_delay, X, Y and an iteration number (\"interval_num\").\n",
    "    \n",
    "    Only the first 10 intervals per participant are processed.\n",
    "    \n",
    "    Returns a DataFrame with the merged data.\n",
    "    \"\"\"\n",
    "    df_cal = process_calibrated_file(cal_file)\n",
    "    df_intervals = process_saccade_messages_with_participant(msg_file)\n",
    "    \n",
    "    merged_rows = []\n",
    "    # Process only the first 10 intervals per participant.\n",
    "    for i, interval in enumerate(df_intervals.itertuples(), start=1):\n",
    "        if i > 10:\n",
    "            break\n",
    "        start, end = interval.start, interval.end\n",
    "        # Select calibrated gaze data rows within this saccade interval.\n",
    "        df_interval = df_cal[(df_cal[\"Time\"] >= start) & (df_cal[\"Time\"] <= end)].copy()\n",
    "        if df_interval.empty:\n",
    "            continue\n",
    "        # Annotate these rows with the saccade properties and the interval number.\n",
    "        df_interval[\"time_delay\"] = interval.time_delay\n",
    "        df_interval[\"X\"] = interval.X\n",
    "        df_interval[\"Y\"] = interval.Y\n",
    "        df_interval[\"interval_num\"] = i\n",
    "        merged_rows.append(df_interval)\n",
    "    \n",
    "    if merged_rows:\n",
    "        return pd.concat(merged_rows, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# def main():\n",
    "# Collect calibrated gaze files and message files.\n",
    "cal_files = glob.glob(\"../../tiny_data/gaze_data_v6/gaze_directions_calibrated_*.txt\")\n",
    "msg_files = glob.glob(\"../../tiny_data/gaze_data_v6/gaze_messages_*.txt\")\n",
    "\n",
    "# Build a mapping from participant id to its message file.\n",
    "msg_dict = {}\n",
    "for mf in msg_files:\n",
    "    m = re.search(r\"(P\\d+)\", os.path.basename(mf))\n",
    "    if m:\n",
    "        participant_id = m.group(1)\n",
    "        msg_dict[participant_id] = mf\n",
    "\n",
    "merged_list = []\n",
    "for cf in cal_files:\n",
    "    m = re.search(r\"(P\\d+)\", os.path.basename(cf))\n",
    "    if not m:\n",
    "        continue\n",
    "    participant_id = m.group(1)\n",
    "    if participant_id in msg_dict:\n",
    "        merged = merge_saccade_intervals_with_calibrated(cf, msg_dict[participant_id])\n",
    "        if not merged.empty:\n",
    "            merged_list.append(merged)\n",
    "    else:\n",
    "        print(f\"No message file found for participant {participant_id}\")\n",
    "\n",
    "if merged_list:\n",
    "    df_final = pd.concat(merged_list, ignore_index=True)\n",
    "    df_final = df_final.sort_values([\"participants\", \"Time\"]).reset_index(drop=True)\n",
    "    df_final.to_csv(\"../../processed_data/processed_data_tiny_task_saccades_all.csv\", index=False)\n",
    "    print(\"Merged Data:\")\n",
    "    print(df_final.head(20))\n",
    "else:\n",
    "    print(\"No data merged.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
